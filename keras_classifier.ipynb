{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "\n",
    "from keras.optimizers import SGD, rmsprop\n",
    "\n",
    "import os;\n",
    "import os.path;\n",
    "import pickle;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "home = expanduser(\"~\");\n",
    "files_data_dir = home + \"/workspace/machinelearning/datasets/dogs_vs_cats/\";\n",
    "\n",
    "train_data_dir = files_data_dir + \"train/\";\n",
    "test_data_dir = files_data_dir + \"test/\";\n",
    "\n",
    "cats_dir = \"cats/\";\n",
    "dogs_dir = \"dogs/\";\n",
    "\n",
    "num_train_samples = 2048;\n",
    "num_test_samples = 2048;\n",
    "num_epoch = 50;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_filters = {\n",
    "    'wc1' : 32,\n",
    "    'wc2' : 32,\n",
    "    'wc3' : 64,\n",
    "    'wc4' : 64,\n",
    "    'fc1' : 64,\n",
    "    'fc2' : 1,\n",
    "}\n",
    "\n",
    "\n",
    "filter_size = {\n",
    "    'wc1' : 3,\n",
    "    'wc2' : 3,\n",
    "    'wc3' : 3,\n",
    "    'wc4' : 3,\n",
    "}\n",
    "\n",
    "input_size = {\n",
    "    'wc1' : (250, 250, 3),\n",
    "    'wc2' : (125, 125, 32),\n",
    "    'wc3' : (63, 63, 32),\n",
    "    'wc4' : (16, 16, 64),\n",
    "}\n",
    "\n",
    "strides = {\n",
    "    \n",
    "    'wc1' : (1, 1),\n",
    "    'wc2' : (1, 1),\n",
    "    'wc3' : (1, 1),\n",
    "    'wc4' : (1, 1),\n",
    "}\n",
    "\n",
    "activation_type = {\n",
    "    'wc1' : 'relu',\n",
    "    'wc2' : 'relu',\n",
    "    'wc3' : 'relu',\n",
    "    'wc4' : 'relu',\n",
    "    'fc1' : 'relu',\n",
    "    'fc2' : 'sigmoid',\n",
    "}\n",
    "\n",
    "pool_ratio = {\n",
    "    'wc1' : (2, 2),\n",
    "    'wc2' : (2, 2),\n",
    "    'wc3' : (2, 2),\n",
    "    'wc4' : (2, 2),\n",
    "}\n",
    "\n",
    "dropout_ratio = {\n",
    "    'fc1' : 0.5,\n",
    "}\n",
    "\n",
    "init_type = 'glorot_normal';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential();\n",
    "\n",
    "\n",
    "\n",
    "conv1 = Convolution2D(num_filters['wc1'], filter_size['wc1'], filter_size['wc1'], input_shape=input_size['wc1'], subsample=strides['wc1'], init=init_type);\n",
    "model.add(conv1);\n",
    "\n",
    "act1 = Activation(activation_type['wc1']);\n",
    "model.add(act1);\n",
    "\n",
    "pool1 = MaxPooling2D(pool_size=pool_ratio['wc1']);\n",
    "model.add(pool1);\n",
    "\n",
    "\n",
    "\n",
    "conv2 = Convolution2D(num_filters['wc2'], filter_size['wc2'], filter_size['wc2'], input_shape=input_size['wc2'], subsample=strides['wc2'], init=init_type);\n",
    "model.add(conv2);\n",
    "\n",
    "act2 = Activation(activation_type['wc2']);\n",
    "model.add(act2);\n",
    "\n",
    "pool2 = MaxPooling2D(pool_size=pool_ratio['wc2']);\n",
    "model.add(pool2);\n",
    "\n",
    "\n",
    "\n",
    "conv3 = Convolution2D(num_filters['wc3'], filter_size['wc3'], filter_size['wc3'], input_shape=input_size['wc3'], subsample=strides['wc3'], init=init_type);\n",
    "model.add(conv3);\n",
    "\n",
    "act3 = Activation(activation_type['wc3']);\n",
    "model.add(act3);\n",
    "\n",
    "pool3 = MaxPooling2D(pool_size=pool_ratio['wc3']);\n",
    "model.add(pool3);\n",
    "\n",
    "\n",
    "\n",
    "#conv4 = Convolution2D(num_filters['wc4'], filter_size['wc4'], filter_size['wc4'], input_shape=input_size['wc4'], subsample=strides['wc4']);\n",
    "#model.add(conv4);\n",
    "\n",
    "#act4 = Activation(activation_type['wc4']);\n",
    "#model.add(act4);\n",
    "\n",
    "#pool4 = MaxPooling2D(pool_size=pool_ratio['wc4']);\n",
    "#model.add(pool4);\n",
    "\n",
    "\n",
    "model.add(Flatten());\n",
    "\n",
    "\n",
    "\n",
    "fc1 = Dense(num_filters['fc1'], init=init_type);\n",
    "model.add(fc1);\n",
    "\n",
    "act3 = Activation(activation_type['fc1']);\n",
    "model.add(act3);\n",
    "\n",
    "drop1 = Dropout(dropout_ratio['fc1']);\n",
    "model.add(drop1);\n",
    "\n",
    "\n",
    "\n",
    "fc2 = Dense(num_filters['fc2'], init=init_type);\n",
    "model.add(fc2);\n",
    "\n",
    "act4 = Activation(activation_type['fc2']);\n",
    "model.add(act4);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_width = 250;\n",
    "img_height = 250;\n",
    "\n",
    "data_batch_size = 64;\n",
    "\n",
    "data_class_mode = 'binary';\n",
    "\n",
    "\n",
    "loss_func = 'binary_crossentropy';\n",
    "\n",
    "optimizer_func = 'sgd';\n",
    "\n",
    "metric_types = ['accuracy'];\n",
    "\n",
    "learning_rate = 0.001;\n",
    "\n",
    "decay_rate = 1e-10;\n",
    "\n",
    "\n",
    "data_rescale_ratio = 1./255;\n",
    "\n",
    "data_sheer_range = 0.2;\n",
    "\n",
    "data_zoom_range = 0.2;\n",
    "\n",
    "data_horizontal_flip = True;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#opt = SGD(lr=learning_rate, decay=decay_rate);\n",
    "opt = 'adadelta';\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['binary_accuracy'])\n",
    "\n",
    "\n",
    "#model.load_weights('model_sgd_86')\n",
    "train_datagen = ImageDataGenerator(rescale = data_rescale_ratio, shear_range=data_sheer_range, zoom_range=data_zoom_range, horizontal_flip=data_horizontal_flip);\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = data_rescale_ratio);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 images belonging to 2 classes.\n",
      "Found 5000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(train_data_dir, target_size=(img_width, img_height), batch_size=data_batch_size, class_mode=data_class_mode);\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(test_data_dir, target_size=(img_width, img_height), batch_size=data_batch_size, class_mode=data_class_mode);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2048/2048 [==============================] - 197s - loss: 0.6936 - binary_accuracy: 0.5034 - val_loss: 0.6924 - val_binary_accuracy: 0.5107\n",
      "Epoch 2/50\n",
      "2048/2048 [==============================] - 202s - loss: 0.6923 - binary_accuracy: 0.5249 - val_loss: 0.6927 - val_binary_accuracy: 0.5117\n",
      "Epoch 3/50\n",
      "2048/2048 [==============================] - 196s - loss: 0.6927 - binary_accuracy: 0.5078 - val_loss: 0.6915 - val_binary_accuracy: 0.5112\n",
      "Epoch 4/50\n",
      "2048/2048 [==============================] - 195s - loss: 0.6924 - binary_accuracy: 0.5283 - val_loss: 0.6921 - val_binary_accuracy: 0.4966\n",
      "Epoch 5/50\n",
      "2048/2048 [==============================] - 201s - loss: 0.6909 - binary_accuracy: 0.5420 - val_loss: 0.6869 - val_binary_accuracy: 0.5282\n",
      "Epoch 6/50\n",
      "2048/2048 [==============================] - 198s - loss: 0.6891 - binary_accuracy: 0.5308 - val_loss: 0.6861 - val_binary_accuracy: 0.5264\n",
      "Epoch 7/50\n",
      "2048/2048 [==============================] - 200s - loss: 0.6877 - binary_accuracy: 0.5698 - val_loss: 0.6778 - val_binary_accuracy: 0.5749\n",
      "Epoch 8/50\n",
      "2048/2048 [==============================] - 196s - loss: 0.6772 - binary_accuracy: 0.5791 - val_loss: 0.6725 - val_binary_accuracy: 0.5752\n",
      "Epoch 9/50\n",
      "2048/2048 [==============================] - 199s - loss: 0.6797 - binary_accuracy: 0.5786 - val_loss: 0.6724 - val_binary_accuracy: 0.5968\n",
      "Epoch 10/50\n",
      "2016/2048 [============================>.] - ETA: 2s - loss: 0.6947 - binary_accuracy: 0.5779"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/keras/engine/training.py:1480: UserWarning: Epoch comprised more than `samples_per_epoch` samples, which might affect learning results. Set `samples_per_epoch` correctly to avoid this warning.\n",
      "  warnings.warn('Epoch comprised more than '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2080/2048 [==============================] - 196s - loss: 0.6938 - binary_accuracy: 0.5788 - val_loss: 0.6735 - val_binary_accuracy: 0.5991\n",
      "Epoch 11/50\n",
      "2048/2048 [==============================] - 196s - loss: 0.6636 - binary_accuracy: 0.6045 - val_loss: 0.6447 - val_binary_accuracy: 0.6386\n",
      "Epoch 12/50\n",
      "2048/2048 [==============================] - 478s - loss: 0.6634 - binary_accuracy: 0.6021 - val_loss: 0.6290 - val_binary_accuracy: 0.6357\n",
      "Epoch 13/50\n",
      "2048/2048 [==============================] - 538s - loss: 0.6550 - binary_accuracy: 0.6250 - val_loss: 0.6458 - val_binary_accuracy: 0.6284\n",
      "Epoch 14/50\n",
      "2048/2048 [==============================] - 202s - loss: 0.6433 - binary_accuracy: 0.6245 - val_loss: 0.6310 - val_binary_accuracy: 0.6372\n",
      "Epoch 15/50\n",
      "2048/2048 [==============================] - 203s - loss: 0.6318 - binary_accuracy: 0.6323 - val_loss: 0.6189 - val_binary_accuracy: 0.6420\n",
      "Epoch 16/50\n",
      "2048/2048 [==============================] - 211s - loss: 0.6307 - binary_accuracy: 0.6479 - val_loss: 0.6304 - val_binary_accuracy: 0.6255\n",
      "Epoch 17/50\n",
      "2048/2048 [==============================] - 423s - loss: 0.6175 - binary_accuracy: 0.6392 - val_loss: 0.5960 - val_binary_accuracy: 0.6770\n",
      "Epoch 18/50\n",
      "2048/2048 [==============================] - 196s - loss: 0.6129 - binary_accuracy: 0.6558 - val_loss: 0.6008 - val_binary_accuracy: 0.6772\n",
      "Epoch 19/50\n",
      "2048/2048 [==============================] - 675s - loss: 0.6121 - binary_accuracy: 0.6519 - val_loss: 0.5867 - val_binary_accuracy: 0.6873\n",
      "Epoch 20/50\n",
      "2080/2048 [==============================] - 528s - loss: 0.6166 - binary_accuracy: 0.6591 - val_loss: 0.5779 - val_binary_accuracy: 0.6841\n",
      "Epoch 21/50\n",
      "2048/2048 [==============================] - 198s - loss: 0.5800 - binary_accuracy: 0.6836 - val_loss: 0.5555 - val_binary_accuracy: 0.7082\n",
      "Epoch 22/50\n",
      "2048/2048 [==============================] - 201s - loss: 0.5929 - binary_accuracy: 0.6826 - val_loss: 0.5911 - val_binary_accuracy: 0.6934\n",
      "Epoch 23/50\n",
      "2048/2048 [==============================] - 203s - loss: 0.5894 - binary_accuracy: 0.6899 - val_loss: 0.5596 - val_binary_accuracy: 0.7087\n",
      "Epoch 24/50\n",
      "2048/2048 [==============================] - 205s - loss: 0.6011 - binary_accuracy: 0.6758 - val_loss: 0.5597 - val_binary_accuracy: 0.7266\n",
      "Epoch 25/50\n",
      "2048/2048 [==============================] - 201s - loss: 0.5971 - binary_accuracy: 0.6831 - val_loss: 0.5759 - val_binary_accuracy: 0.7096\n",
      "Epoch 26/50\n",
      "2048/2048 [==============================] - 220s - loss: 0.5931 - binary_accuracy: 0.6812 - val_loss: 0.5512 - val_binary_accuracy: 0.7007\n",
      "Epoch 27/50\n",
      "2048/2048 [==============================] - 199s - loss: 0.5941 - binary_accuracy: 0.6763 - val_loss: 0.5418 - val_binary_accuracy: 0.7227\n",
      "Epoch 28/50\n",
      "2048/2048 [==============================] - 200s - loss: 0.5604 - binary_accuracy: 0.7104 - val_loss: 0.6329 - val_binary_accuracy: 0.6221\n",
      "Epoch 29/50\n",
      "2048/2048 [==============================] - 200s - loss: 0.5833 - binary_accuracy: 0.6938 - val_loss: 0.5410 - val_binary_accuracy: 0.7212\n",
      "Epoch 30/50\n",
      "2080/2048 [==============================] - 207s - loss: 0.5718 - binary_accuracy: 0.6851 - val_loss: 0.5357 - val_binary_accuracy: 0.7174\n",
      "Epoch 31/50\n",
      " 896/2048 [============>.................] - ETA: 83s - loss: 0.5528 - binary_accuracy: 0.7299"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-cc6be6282164>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_train_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_val_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_test_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe, **kwargs)\u001b[0m\n\u001b[1;32m    880\u001b[0m                                         \u001b[0mmax_q_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_q_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m                                         \u001b[0mnb_worker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_worker\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m                                         pickle_safe=pickle_safe)\n\u001b[0m\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m     def evaluate_generator(self, generator, val_samples,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe)\u001b[0m\n\u001b[1;32m   1459\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   1460\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1461\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   1462\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1463\u001b[0m                     \u001b[0m_stop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1237\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1240\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0mupdated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 382\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    383\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    653\u001b[0m     \u001b[0mmovers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_with_movers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m     results = self._do_run(handle, target_list, unique_fetches,\n\u001b[0;32m--> 655\u001b[0;31m                            feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[0;31m# User may have fetched the same tensor multiple times, but we\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    721\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m--> 723\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m    724\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m    728\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m    710\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m    711\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 712\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m    713\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit_generator(train_generator, samples_per_epoch=num_train_samples, nb_epoch=num_epoch, validation_data=test_generator, nb_val_samples=num_test_samples);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
